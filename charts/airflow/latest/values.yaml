auth:
  username: "admin" # Change to your desired admin username
  password: "admin" # Set a strong password or use existingSecret
  fernetKey: "z3_Wy_BmW8g2rYdbxZl0Nuf1JyfgFzOkn_rwDJIj_E4=" # Generate a Fernet key (e.g., via `python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"`)
  secretKey: "LaF21zITR7Iikq6sEzvotbHDZBEf7JTpQN6TT2rwB94=" # Generate a secret key for Flask (e.g., via `openssl rand -base64 32`)
  jwtSecretKey: "peHj5O1Smbj9Q+CMIJGktlYmbwYlPadKjrr0SwFc6sWV+q933UlwleXl5mRizKL3ZC61hrRU9rD5I2aVxI2V8Q==" # Generate a JWT secret key if using JWT

# Airflow configuration
executor: LocalExecutor # Use CeleryExecutor for distributed tasks; change to KubernetesExecutor if needed
loadExamples: true # Disable example DAGs in production
#configuration: {} # Customize Airflow settings if needed, e.g., core.dags_folder
#overrideConfiguration: {} # Override specific settings
#localSettings: "" # Add custom airflow_local_settings.py if needed
#existingConfigmap: "" # Use if storing config in a ConfigMap

extraVolumeMounts:
  - name: projects
    mountPath: /opt/airflow
    readOnly: false

extraVolumes:
  - name: projects
    hostPath: ""
    type: Directory

# Airflow webserver
web:
  baseUrl: "http://airflow.local" # Set to your external URL


ingress:
  enabled: true
  hostname: "airflow.local" # Your domain
  path: "/"
  ingressClassName: "nginx" # Or your preferred Ingress controller

postgresql:
  enabled: false

# External PostgreSQL (if postgresql.enabled=false)
externalDatabase:
  host: "postgres-postgresql.postgres.svc.cluster.local"
  port: 5432
  user: "postgres"
  database: "airflow"
  password: "password"

# Redis (internal)
redis:
  enabled: false

# External Redis (if redis.enabled=false)
externalRedis:
  host: "redis-master.redis.svc.cluster.local"
  port: 6379
  password: "admin" # Set to your Redis password